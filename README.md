# self_MT

马尔科夫性，是俄国数学家安德雷·马尔科夫得名。是指未来状态的概率分布仅与当前状态有关，与过去状态条件独立。
机器翻译解码过程不具备马尔科夫性，因此动态规划算法不适用于解码过程。启发式搜索beam search 是目前实验效果较理想的解码策略，但贪心算法
并不一定能得到全局最优序列。
通过分析，概率差异标准化，在解码过程，采用动态beam size，对无效节点进行剪枝，又保留了获得全局最优解的可能性。

克林闭包

解码错误，或问题较多的地方是被BPE切分的地方。
分析罕见词，分词结果
            BPE 切分结果
            翻译结果 之间的关联
猜想：中英翻译
      直接分词训练，unk，词表大小问题。
      sentencepiece-unigram 效果是否与直接分词训练结果差不大。
  中文句子切分为更细粒度，比如char 是否会使得中英翻译效果更好。因为对sentencepiece-unigram，再次进行bpe分词，其他条件不变，效果变好了。还有分词后+bpe切分也只不过把词切的更细。
  或者中文切分粒度与英文单词的意思对应上，英文译文指导中文分词。
  测试 sentecepiece-unigram-bpe，效果与 sentecepiece-unigram 比有提升，查看词表；猜测中英翻译，unigram 切分单词较长，导致中到英一对多翻译；分词后的bpe切分更细，中英翻译多对一翻译，较容易学习映射关系；
  nist 测试集 BLEU 得分区别不大，研报测试集有提升，猜测研报测试集与通用测试集相比，中文分词导致的问题更多？
  不采用分词，或者说是高频词切分+低频词采用char类型训练。
  
  翻译解码时，高频词对应高频词，中频词对应中频词，低频词对应低频词，用来剪枝，或者不同领域词加权
  翻译解码时，ffn 的隐藏层维度设置得与目标端词表一致，翻译效果是否会更好。
  
  正向翻译语料的质量，使得模型效果快速逼近google翻译。
  
  
  
